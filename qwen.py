#!/usr/bin/env python3
"""
ðŸŽ¨ Qwen Image for macOS - Native text-to-image generator

Simple, fast, Apple Siliconâ€“optimized. Just works. No complexity.
"""

import torch
import click
import time
from pathlib import Path
import platform
import warnings
import subprocess
from diffusers.utils import logging as diffusers_logging
from transformers.utils import logging as transformers_logging


def _configure_logging():
    """Configure library loggers to reduce noisy warnings by default.

    Users can opt into verbose logs by setting QWEN_VERBOSE=1 in the
    environment before running the CLI.
    """
    import os
    verbose = os.environ.get("QWEN_VERBOSE") in {"1", "true", "True"}
    if verbose:
        diffusers_logging.set_verbosity_warning()
        transformers_logging.set_verbosity_warning()
        # Show warnings normally in verbose mode
        warnings.filterwarnings("default")
    else:
        # Keep third-party libraries quiet unless something is wrong
        diffusers_logging.set_verbosity_error()
        transformers_logging.set_verbosity_error()
        # Hide common library chatter that users can't act on
        warnings.filterwarnings("ignore", category=UserWarning)
        warnings.filterwarnings("ignore", category=FutureWarning)


_configure_logging()


def setup_device():
    """Get the best available device."""
    if torch.backends.mps.is_available():
        print("ðŸš€ Using Apple Silicon GPU (MPS)")
        return torch.device("mps"), torch.bfloat16
    else:
        print("ðŸ’» Using CPU")
        return torch.device("cpu"), torch.float32


def load_generation_pipeline():
    """Load generation pipeline with Lightning LoRA."""
    print("ðŸ“¥ Loading Qwen Image model (first run downloads ~20GB)...")
    start = time.time()
    
    try:
        from diffusers import QwenImagePipeline
        device, dtype = setup_device()
        
        pipeline = QwenImagePipeline.from_pretrained(
            "Qwen/Qwen-Image",
            dtype=dtype,
        ).to(device)

        # Reduce memory spikes that can slow MPS
        pipeline.enable_attention_slicing()
        pipeline.enable_vae_tiling()
        
        load_time = time.time() - start
        print(f"âœ… Ready in {load_time:.1f}s")
        return pipeline, device
        
    except (ImportError, OSError, RuntimeError, ValueError) as err:
        raise click.ClickException(
            f"Failed to load model: {err}\nTry: pip install --upgrade diffusers transformers"
        )




def save_and_preview(image, filename=None):
    """Save image and auto-preview on Mac."""
    output_dir = Path.home() / "qwen-images"
    output_dir.mkdir(exist_ok=True)
    
    if not filename:
        timestamp = int(time.time())
        filename = f"qwen_{timestamp}.png"
    
    if not filename.endswith(('.png', '.jpg', '.jpeg')):
        filename += '.png'
    
    output_path = output_dir / filename
    image.save(output_path, optimize=True)
    print(f"ðŸ’¾ Saved: {output_path}")
    
    # Auto-preview on Mac
    if platform.system() == "Darwin":
        import subprocess
        try:
            subprocess.run(["open", str(output_path)], check=True)
            print("ðŸ‘€ Opening preview...")
        except subprocess.SubprocessError:
            # Preview failed, but image was still saved successfully
            pass
    
    return output_path


@click.group()
def cli():
    """ðŸŽ¨ Qwen Image - Native text-to-image for macOS
    
    Fast AI image generation optimized for Apple Silicon.
    
    Examples:
      python qwen.py generate "a beautiful mountain landscape"
      python qwen.py test
    """
    pass


@cli.command()
@click.argument('prompt')
@click.option('-o', '--output', help='Output filename')  
@click.option('--steps', default=20, help='Inference steps (10=stylistic, 20=quality, 30=max)')
@click.option('--seed', type=int, help='Random seed')
@click.option('--size', default='1024x1024', help='Image size (e.g. 1024x1024)')
def generate(prompt, output, steps, seed, size):
    """Generate a new image from text.
    
    Examples:
      python qwen.py generate "a cyberpunk cityscape at night"
      python qwen.py generate "cute corgi puppy" --steps 20 --seed 42
    """
    print(f"ðŸŽ¨ Generating: {prompt}")
    
    # Parse size
    try:
        width, height = map(int, size.split('x'))
    except (ValueError, AttributeError):
        raise click.ClickException(
            f"Invalid size format: {size} (use WxH like 1024x1024)"
        )
    
    # Load pipeline
    pipeline, device = load_generation_pipeline()
    
    # Setup generator
    generator = None
    if seed is not None:
        generator = torch.Generator(device="cpu" if device.type == "mps" else device)  
        generator.manual_seed(seed)
        print(f"ðŸŽ² Seed: {seed}")
    
    # Show settings
    if steps <= 10:
        print(f"ðŸŽ¨ Quick mode ({steps} steps) - stylistic results")
    elif steps <= 25:
        print(f"ðŸŽ¨ Quality mode ({steps} steps) - fully formed")
    else:
        print(f"ðŸŽ† Maximum quality mode ({steps} steps)")
    
    print(f"ðŸ“ Size: {width}x{height}")
    
    # Generate
    print("Generating...")
    start = time.time()
    
    result = pipeline(
        prompt=prompt,
        num_inference_steps=steps,
        width=width,
        height=height,
        generator=generator,
    )
    
    gen_time = time.time() - start
    
    # Save and preview
    image = result.images[0]
    output_path = save_and_preview(image, output)
    
    print(f"âœ… Generated in {gen_time:.1f}s")
    print(f"ðŸ“ Location: {output_path.parent}")




@cli.command()
def test():
    """Quick test - generates a demo image."""
    print("ðŸ§ª Testing Qwen Image on your Mac...")
    
    # Check device
    device, dtype = setup_device()
    if device.type == "mps":
        print("âœ… Apple Silicon GPU ready")
    else:
        print("âš ï¸ Using CPU (will be slower)")
    
    # Quick demo generation
    try:
        print("ðŸŽ¨ Generating demo image...")
        pipeline, _ = load_generation_pipeline()
        
        start_time = time.time()
        result = pipeline(
            prompt="a cute robot waving hello",
            num_inference_steps=10,
            width=512,
            height=512,
        )
        gen_time = time.time() - start_time
        
        # Save and show
        test_image = result.images[0]
        output_dir = Path.home() / "qwen-images"
        output_dir.mkdir(exist_ok=True)
        test_path = output_dir / "demo.png"
        test_image.save(test_path)
        
        print(f"ðŸŽ‰ Demo image generated in {gen_time:.1f}s!")
        print(f"ðŸ“ Saved: {test_path}")
        print("ðŸ“ Note: This is a quick demo (10 steps). Use --steps 20 for higher quality!")
        
        # Auto-open on Mac
        if platform.system() == "Darwin":
            import subprocess
            subprocess.run(["open", str(test_path)], check=True)
            print("ðŸ‘€ Opening demo image...")
            
        print("\nðŸš€ Ready! Try: python qwen.py generate 'your prompt here' --steps 20")
        
    except (RuntimeError, OSError, ValueError) as err:
        raise click.ClickException(
            f"Test failed: {err}\nTry: pip install --upgrade torch diffusers transformers"
        )


@cli.command()
def status():
    """Show system status and tips."""
    device, dtype = setup_device()
    
    print(f"ðŸ–¥ï¸  System: {platform.platform()}")
    print(f"ðŸ”¥ Device: {device} ({dtype})")
    print(f"ðŸ§  PyTorch: {torch.__version__}")
    
    if device.type == "mps":
        print("âœ… Apple Silicon GPU acceleration active")
    else:
        print("âš ï¸  Using CPU (slower)")
    
    # Check output directory
    output_dir = Path.home() / "qwen-images" 
    print(f"ðŸ“ Output: {output_dir}")
    if output_dir.exists():
        images = list(output_dir.glob("*.png")) + list(output_dir.glob("*.jpg"))
        print(f"ðŸ–¼ï¸  Images: {len(images)} created")
    
    print("\nðŸ’¡ Tips:")
    print("  â€¢ Use --steps 10 for quick stylistic results")
    print("  â€¢ Use --steps 20 for fully formed, quality images")
    print("  â€¢ Use --steps 30 for maximum quality")
    print("  â€¢ Run 'python qwen.py test' to verify everything works")




if __name__ == '__main__':
    cli()
